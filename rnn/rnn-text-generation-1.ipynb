{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Lab: Generating Text with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**Recurrent Neural Network**(RNN) is a form of machine learning algorithm that is ideal for sequential data such as text, time series, financial data, speech, audio, video among others.  \n",
    "\n",
    "To run this lab we will be using a python library called **textgenrnn**\n",
    "This library will easily train your own text-generating neural network of any size and complexity on any text dataset with a few lines of code.\" textgenrnn is authored by Max Woolf, an Associate Data Scientist at BuzzFeed, and former Apple Software QA Engineer.\n",
    "\n",
    "**textgenrnn** is a Python 3 module on top of Keras/TensorFlow for creating [char-rnns](https://github.com/karpathy/char-rnn), with many cool features:\n",
    "\n",
    " - A modern neural network architecture which utilizes new techniques as attention-weighting and skip-embedding to accelerate training and improve model quality.\n",
    " - Train on and generate text at either the character-level or word-level.\n",
    " - Configure RNN size, the number of RNN layers, and whether to use bidirectional RNNs.\n",
    " - Train on any generic input text file, including large files.\n",
    " - Train models on a GPU and then use them to generate text with a CPU.\n",
    " - Utilize a powerful CuDNN implementation of RNNs when trained on the GPU, which massively speeds up training time as opposed to typical LSTM implementations.\n",
    " - Train the model using contextual labels, allowing it to learn faster and produce better results in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the repository [here](https://github.com/minimaxir/textgenrnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Google COLAB :  False\n"
     ]
    }
   ],
   "source": [
    "# Code to run on Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print (\"Running in Google COLAB : \", IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "## Turning this off for now to prevent error in Colab\n",
    "# try:\n",
    "#   # %tensorflow_version only exists in Colab.\n",
    "#   %tensorflow_version 2.x\n",
    "# except Exception:\n",
    "#   pass\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print (keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install textgenRNN\n",
    "\n",
    "!pip install -q textgenrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**textgenrnn** will use a default model unless you specify the size and complexity of the neural network with a wide variety of parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn\n",
    "\n",
    "textgen = textgenrnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Train Model\n",
    "\n",
    "Select text to train on.   Uncomment out one of the url to train train data on they are of the following:\n",
    " - 2018 Trump State of the Union Address\n",
    " - 2009 Obama State of the Union Address\n",
    " -  Collection of Trump tweets(Largest data set will take a while to train on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the number of epochs you wish to train on.  For this example we will be using 1 epoch but to get better results increase the epochs.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## obama state of the union\n",
    "data_location = 'https://elephantscale-public.s3.amazonaws.com/data/text/state-of-the-unions/2018-Trump.txt'\n",
    "\n",
    "## trump stou-2020\n",
    "# data_location = 'https://elephantscale-public.s3.amazonaws.com/data/text/state-of-the-unions/2020-Trump.txt'\n",
    "\n",
    "## trump tweets \n",
    "# ~20k tweets, Note : Training will take a while (on CPU = 1 hr)\n",
    "# data_location = 'https://elephantscale-public.s3.amazonaws.com/data/text/tweets/Trump-tweets.txt'\n",
    "\n",
    "## tiny shakespeare (1.1 M)\n",
    "## training time on colab GPU = ~ 2 mins,   CPU ( 8 core, 4GHz) = 30 mins\n",
    "# data_location = 'https://elephantscale-public.s3.amazonaws.com/data/text/books/tiny-shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://elephantscale-public.s3.amazonaws.com/data/text/state-of-the-unions/2018-Trump.txt\n",
      "32768/30307 [================================] - 0s 2us/step\n",
      "/home/ubuntu/.keras/datasets/2018-Trump.txt\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "data_location_local  = keras.utils.get_file(fname=os.path.basename(data_location),\n",
    "                                           origin=data_location)\n",
    "print (data_location_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648 texts collected.\n",
      "Training on 30,236 character sequences.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.5007####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fix to help me our candidal and the third car court to commune the same country.\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "is if Youth to reps\n",
      "\n",
      "We must salcenced them, we will receiving Underviewed Peterble.\n",
      "\n",
      "dofbend on the Cyrezeer Sorget, when he loostined yours\n",
      "\n",
      "236/236 [==============================] - 71s 300ms/step - loss: 1.4999\n",
      "CPU times: user 7min 3s, sys: 8min 14s, total: 15min 17s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "textgen.train_from_file(data_location_local, num_epochs=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "receined to tax claimed For The right and a new hundred and Methlay etc.\n",
      "\n",
      "None\n",
      "CPU times: user 23.1 s, sys: 33 s, total: 56.1 s\n",
      "Wall time: 4.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "print (textgen.generate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change some simple paramters such as **temperature** (the textgenrnn default is 0.5) to get some more creative text.\n",
    "**Temperature** represents the “creativity” of the text, it allows the model to make increasingly suboptimal prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:03<00:12,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manday was are standards of tonight, Steve Pizzaer, Some of\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:08<00:11,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inteined expanding with the Unitue of the speciest. They pushiluus to people endansed to keep.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:10<00:06,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more of the grave for the tree live out\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:14<00:03,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "immigger, dusting versions called the countrial. They will return to expect\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alternates, including the booby of\n",
      "\n",
      "None\n",
      "CPU times: user 1min 28s, sys: 2min 7s, total: 3min 36s\n",
      "Wall time: 16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "print (textgen.generate(5, temperature=0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Experiment with Different Texts\n",
    "\n",
    "- You will not get quality generated text 100% of the time, even with a heavily-trained neural network. \n",
    "- Results will vary greatly between datasets. Because the pretrained neural network is relatively small, it cannot store as much data.  For best results, use a dataset with at least 2,000-5,000 documents. If a dataset is smaller, you'll need to train it for longer by setting num_epochs higher when calling a training method and/or training a new model from scratch. \n",
    "- A GPU is not required to retrain textgenrnn, but it will take much longer to train on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
