{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Using Recurrent Neural Network (RNN) to process the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Google COLAB :  False\n"
     ]
    }
   ],
   "source": [
    "# Install the package for running tensorboard on google colaboration\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print (\"Running in Google COLAB : \", IN_COLAB)\n",
    "\n",
    "\n",
    "# if IN_COLAB == True:\n",
    "#     from tensorboardcolab import *\n",
    "#     !pip install -U tensorboardcolab\n",
    "# # Load the TensorBoard notebook extension\n",
    "#     %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can used your own dataset with english text\n",
    "data_location = \"/data/text/state-of-the-unions/2009-Obama.txt\"\n",
    "# data_location = 'https://elephantscale-public.s3.amazonaws.com/data/text/state-of-the-unions/2009-Obama.txt'\n",
    "\n",
    "\n",
    "with open( data_location, \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If the above fails, try this\n",
    "\n",
    "# !wget 'https://elephantscale-public.s3.amazonaws.com/data/text/state-of-the-unions/2009-Obama.txt'\n",
    "\n",
    "# with open('2009-Obama.txt' , \"r\") as f:\n",
    "#     text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33794\n",
      "Madame Speaker, Mr. Vice President, Members of Congress, and the First Lady of\n",
      "the United States:\n",
      "\n",
      "I've come here tonight not only to address the distinguished men and women in\n",
      "this great chamber, but to speak frankly and directly to the men and women who\n",
      "sent us here.\n",
      "\n",
      "I know that for many Americans watching right now, the state of our economy is\n",
      "a concern that rises above all others.  And rightly so.  If you haven't been\n",
      "personally affected by this recession, you probably know someone who has -- a\n",
      "friend; a neighbor; a member of your family.  You don't need to hear another\n",
      "list of statistics to know that our economy is in crisis, because you live it\n",
      "every day.  It's the worry you wake up with and the source of sleepless\n",
      "nights.  It's the job you thought you'd retire from but now have lost; the\n",
      "business you built your dreams upon that's now hanging by a thread; the\n",
      "college acceptance letter your child had to put back in the envelope.  The\n",
      "impact of this recession is real, and it is ev\n"
     ]
    }
   ],
   "source": [
    "print(len(text))\n",
    "\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Shape Data\n",
    "\n",
    "### 3.1 - Remove character and create vocabulary\n",
    "\n",
    "<img src=\"../assets/images/rnn_vocab.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 {'a', 'p', 'i', ':', 'y', '0', ';', '3', 'n', 'k', 'd', 'e', '\\n', 'h', '.', '9', 'o', 't', ' ', \"'\", 'x', 'q', '%', 'w', 'b', 'r', 'l', ',', 'g', 'c', 'u', 'v', '7', '/', 'm', '6', 'j', 's', '\"', 'z', 'f'}\n",
      "madame speaker, mr. vice president, members of congress, and the first lady of\n",
      "the united states:\n",
      "\n",
      "i've come here tonight not only to address the distinguished men and women in\n",
      "this great chamber, but to speak frankly and directly to the men and women who\n",
      "sent us here.\n",
      "\n",
      "i know that for many americans watching right now, the state of our economy is\n",
      "a concern that rises above all others.  and rightly so.  if you haven't been\n",
      "personally affected by this recession, you probably know someone who has  a\n",
      "friend; a neighbor; a member of your family.  you don't need to hear another\n",
      "list of statistics to know that our economy is in crisis, because you live it\n",
      "every day.  it's the worry you wake up with and the source of sleepless\n",
      "nights.  it's the job you thought you'd retire from but now have lost; the\n",
      "business you built your dreams upon that's now hanging by a thread; the\n",
      "college acceptance letter your child had to put back in the envelope.  the\n",
      "impact of this recession is real, and it is ever\n"
     ]
    }
   ],
   "source": [
    "import unidecode \n",
    "\n",
    "text = unidecode.unidecode(text)\n",
    "text = text.lower()\n",
    "\n",
    "text = text.replace(\"2\", \"\")\n",
    "text = text.replace(\"1\", \"\")\n",
    "text = text.replace(\"8\", \"\")\n",
    "text = text.replace(\"5\", \"\")\n",
    "text = text.replace(\">\", \"\")\n",
    "text = text.replace(\"<\", \"\")\n",
    "text = text.replace(\"!\", \"\")\n",
    "text = text.replace(\"?\", \"\")\n",
    "text = text.replace(\"-\", \"\")\n",
    "text = text.replace(\"$\", \"\")\n",
    "\n",
    "text = text.strip()\n",
    "\n",
    "vocab = set(text)\n",
    "print(len(vocab), vocab)\n",
    "\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Map each letter to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_to_int {'a': 0, 'p': 1, 'i': 2, ':': 3, 'y': 4, '0': 5, ';': 6, '3': 7, 'n': 8, 'k': 9, 'd': 10, 'e': 11, '\\n': 12, 'h': 13, '.': 14, '9': 15, 'o': 16, 't': 17, ' ': 18, \"'\": 19, 'x': 20, 'q': 21, '%': 22, 'w': 23, 'b': 24, 'r': 25, 'l': 26, ',': 27, 'g': 28, 'c': 29, 'u': 30, 'v': 31, '7': 32, '/': 33, 'm': 34, '6': 35, 'j': 36, 's': 37, '\"': 38, 'z': 39, 'f': 40}\n",
      "\n",
      "int_to_vocab {0: 'a', 1: 'p', 2: 'i', 3: ':', 4: 'y', 5: '0', 6: ';', 7: '3', 8: 'n', 9: 'k', 10: 'd', 11: 'e', 12: '\\n', 13: 'h', 14: '.', 15: '9', 16: 'o', 17: 't', 18: ' ', 19: \"'\", 20: 'x', 21: 'q', 22: '%', 23: 'w', 24: 'b', 25: 'r', 26: 'l', 27: ',', 28: 'g', 29: 'c', 30: 'u', 31: 'v', 32: '7', 33: '/', 34: 'm', 35: '6', 36: 'j', 37: 's', 38: '\"', 39: 'z', 40: 'f'}\n",
      "\n",
      "int for e: 11\n",
      "letter for 11: e\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "vocab_to_int = {l:i for i,l in enumerate(vocab)}\n",
    "int_to_vocab = {i:l for i,l in enumerate(vocab)}\n",
    "\n",
    "print(\"vocab_to_int\", vocab_to_int)\n",
    "print()\n",
    "print(\"int_to_vocab\", int_to_vocab)\n",
    "\n",
    "print(\"\\nint for e:\", vocab_to_int[\"e\"])\n",
    "int_for_e = vocab_to_int[\"e\"]\n",
    "print(\"letter for %s: %s\" % (vocab_to_int[\"e\"], int_to_vocab[int_for_e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34, 0, 10, 0, 34, 11, 18, 37, 1, 11, 0, 9, 11, 25, 27, 18, 34, 25, 14, 18, 31, 2, 29, 11, 18, 1, 25, 11, 37, 2, 10, 11, 8, 17, 27, 18, 34, 11, 34, 24, 11, 25, 37, 18, 16, 40, 18, 29, 16, 8, 28, 25, 11, 37, 37, 27, 18, 0, 8, 10, 18, 17, 13, 11, 18, 40, 2, 25, 37, 17, 18, 26, 0, 10, 4, 18, 16, 40, 12, 17, 13, 11, 18, 30, 8, 2, 17, 11, 10, 18, 37, 17, 0, 17, 11, 37, 3, 12, 12, 2]\n"
     ]
    }
   ],
   "source": [
    "encoded = [vocab_to_int[l] for l in text]\n",
    "encoded_sentence = encoded[:100]\n",
    "\n",
    "print(encoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m', 'a', 'd', 'a', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', 'e', 'r', ',', ' ', 'm', 'r', '.', ' ', 'v', 'i', 'c', 'e', ' ', 'p', 'r', 'e', 's', 'i', 'd', 'e', 'n', 't', ',', ' ', 'm', 'e', 'm', 'b', 'e', 'r', 's', ' ', 'o', 'f', ' ', 'c', 'o', 'n', 'g', 'r', 'e', 's', 's', ',', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'f', 'i', 'r', 's', 't', ' ', 'l', 'a', 'd', 'y', ' ', 'o', 'f', '\\n', 't', 'h', 'e', ' ', 'u', 'n', 'i', 't', 'e', 'd', ' ', 's', 't', 'a', 't', 'e', 's', ':', '\\n', '\\n', 'i']\n"
     ]
    }
   ],
   "source": [
    "decoded_sentence = [int_to_vocab[i] for i in encoded_sentence]\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "madame speaker, mr. vice president, members of congress, and the first lady of\n",
      "the united states:\n",
      "\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "decoded_sentence = \"\".join(decoded_sentence)\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Genrate batch\n",
    "\n",
    "### Sample of one batch\n",
    "\n",
    "<img src=\"../assets/images/rnn_letter.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs [34, 0, 10, 0, 34, 11, 18, 37, 1, 11]\n",
      "Targets [0, 10, 0, 34, 11, 18, 37, 1, 11, 0]\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = encoded, encoded[1:]\n",
    "\n",
    "print(\"Inputs\", inputs[:10])\n",
    "print(\"Targets\", targets[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method used to generate batch in sequence order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34.  0. 10.  0. 34.] [ 0. 10.  0. 34. 11.]\n",
      "[34. 16. 10.  0. 16.] [ 0. 10.  0. 34. 11.]\n"
     ]
    }
   ],
   "source": [
    "def gen_batch(inputs, targets, seq_len, batch_size, noise=0):\n",
    "    # Size of each chunk\n",
    "    chuck_size = (len(inputs) -1)  // batch_size\n",
    "    # Numbef of sequence per chunk\n",
    "    sequences_per_chunk = chuck_size // seq_len\n",
    "\n",
    "    for s in range(0, sequences_per_chunk):\n",
    "        batch_inputs = np.zeros((batch_size, seq_len))\n",
    "        batch_targets = np.zeros((batch_size, seq_len))\n",
    "        for b in range(0, batch_size):\n",
    "            fr = (b*chuck_size)+(s*seq_len)\n",
    "            to = fr+seq_len\n",
    "            batch_inputs[b] = inputs[fr:to]\n",
    "            batch_targets[b] = inputs[fr+1:to+1]\n",
    "            \n",
    "            if noise > 0:\n",
    "                noise_indices = np.random.choice(seq_len, noise)\n",
    "                batch_inputs[b][noise_indices] = np.random.randint(0, vocab_size)\n",
    "            \n",
    "        yield batch_inputs, batch_targets\n",
    "\n",
    "for batch_inputs, batch_targets in gen_batch(inputs, targets, 5, 32, noise=0):\n",
    "    print(batch_inputs[0], batch_targets[0])\n",
    "    break\n",
    "\n",
    "for batch_inputs, batch_targets in gen_batch(inputs, targets, 5, 32, noise=3):\n",
    "    print(batch_inputs[0], batch_targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create model\n",
    "### 4.1 - Create your own layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHot(tf.keras.layers.Layer):\n",
    "    def __init__(self, depth, **kwargs):\n",
    "        super(OneHot, self).__init__(**kwargs)\n",
    "        self.depth = depth\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return tf.one_hot(tf.cast(x, tf.int32), self.depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if the layer works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 50)\n",
      "WARNING:tensorflow:Entity <bound method RnnModel.call of <__main__.RnnModel object at 0x7f4a7bd9de10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method RnnModel.call of <__main__.RnnModel object at 0x7f4a7bd9de10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method OneHot.call of <__main__.OneHot object at 0x7f4a80e20950>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method OneHot.call of <__main__.OneHot object at 0x7f4a80e20950>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "(32, 50, 41)\n",
      "Input letter is: 34.0\n",
      "One hot representation of the letter [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "class RnnModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super(RnnModel, self).__init__()\n",
    "        # Convolutions\n",
    "        self.one_hot = OneHot(len(vocab))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = self.one_hot(inputs)\n",
    "        return output\n",
    "\n",
    "batch_inputs, batch_targets = next(gen_batch(inputs, targets, 50, 32))\n",
    "\n",
    "print(batch_inputs.shape)\n",
    "\n",
    "model = RnnModel(len(vocab))\n",
    "output = model.predict(batch_inputs)\n",
    "\n",
    "print(output.shape)\n",
    "\n",
    "#print(output)\n",
    "\n",
    "print(\"Input letter is:\", batch_inputs[0][0])\n",
    "print(\"One hot representation of the letter\", output[0][0])\n",
    "\n",
    "#assert(output[int(batch_inputs[0][0])]==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Setup the model\n",
    "\n",
    "<img src=\"../assets/images/architecture_rnn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method OneHot.call of <__main__.OneHot object at 0x7f4a7bd7be90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method OneHot.call of <__main__.OneHot object at 0x7f4a7bd7be90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "### Creat the layers\n",
    "\n",
    "# Set the input of the model\n",
    "tf_inputs = tf.keras.Input(shape=(None,), batch_size=64)\n",
    "# Convert each value of the  input into a one encoding vector\n",
    "one_hot = OneHot(len(vocab))(tf_inputs)\n",
    "# Stack LSTM cells\n",
    "rnn_layer1 = tf.keras.layers.LSTM(128, return_sequences=True, stateful=True)(one_hot)\n",
    "rnn_layer2 = tf.keras.layers.LSTM(128, return_sequences=True, stateful=True)(rnn_layer1)\n",
    "# Create the outputs of the model\n",
    "hidden_layer = tf.keras.layers.Dense(128, activation=\"relu\")(rnn_layer2)\n",
    "outputs = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")(hidden_layer)\n",
    "\n",
    "### Setup the model\n",
    "model = tf.keras.Model(inputs=tf_inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Check if we can reset the RNN cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Star by resetting the cells of the RNN\n",
    "model.reset_states()\n",
    "\n",
    "# Get one batch\n",
    "batch_inputs, batch_targets = next(gen_batch(inputs, targets, 50, 64))\n",
    "\n",
    "# Make a first prediction\n",
    "outputs = model.predict(batch_inputs)\n",
    "first_prediction = outputs[0][0]\n",
    "\n",
    "# Reset the states of the RNN states\n",
    "model.reset_states()\n",
    "\n",
    "# Make an other prediction to check the difference\n",
    "outputs = model.predict(batch_inputs)\n",
    "second_prediction = outputs[0][0]\n",
    "\n",
    "# Check if both prediction are equal\n",
    "assert(set(first_prediction)==set(second_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Set the loss and objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 - Set some metrics to track the progress of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "# Accuracy\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 - Set the train method and the predict method in graph mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Make a prediction on all the batch\n",
    "        predictions = model(inputs)\n",
    "        # Get the error/loss on these predictions\n",
    "        loss = loss_object(targets, predictions)\n",
    "    # Compute the gradient which respect to the loss\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # Change the weights of the model\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    # The metrics are accumulate over time. You don't need to average it yourself.\n",
    "    train_loss(loss)\n",
    "    train_accuracy(targets, predictions)\n",
    "\n",
    "@tf.function\n",
    "def predict(inputs):\n",
    "    # Make a prediction on all the batch\n",
    "    predictions = model(inputs)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function train_step at 0x7f4a5adbbe60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
      "WARNING: Entity <function train_step at 0x7f4a5adbbe60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
      "WARNING:tensorflow:Layer one_hot_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method OneHot.call of <__main__.OneHot object at 0x7f4a7bd7be90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method OneHot.call of <__main__.OneHot object at 0x7f4a7bd7be90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/ubuntu/apps/anaconda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f4a546c4e60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f4a546c4e60> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method OneHot.call of <__main__.OneHot object at 0x7f4a7bd7be90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method OneHot.call of <__main__.OneHot object at 0x7f4a7bd7be90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      " Epoch 3999, Train Loss: 0.7701197266578674, Train Accuracy: 77.640396118164065"
     ]
    }
   ],
   "source": [
    "model.reset_states()\n",
    "\n",
    "for epoch in range(4000):\n",
    "    for batch_inputs, batch_targets in gen_batch(inputs, targets, 100, 64, noise=13):\n",
    "        train_step(batch_inputs, batch_targets)\n",
    "    template = '\\r Epoch {}, Train Loss: {}, Train Accuracy: {}'\n",
    "    print(template.format(epoch, train_loss.result(), train_accuracy.result()*100), end=\"\")\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source:\n",
    "https://github.com/thibo73800/tensorflow2.0-examples/blob/master/RNN%20-%20Text%20Generator.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
