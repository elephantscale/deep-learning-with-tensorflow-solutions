{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices Regressions - Minimal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Google COLAB :  False\n"
     ]
    }
   ],
   "source": [
    "## Determine if we are running on google colab\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    RUNNING_IN_COLAB = True\n",
    "except:\n",
    "    RUNNING_IN_COLAB = False\n",
    "\n",
    "print (\"Running in Google COLAB : \", RUNNING_IN_COLAB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '../data/house-prices/house-sales-full.csv'\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "    data_location = 'https://elephantscale-public.s3.amazonaws.com/data/house-prices/house-sales-full.csv'\n",
    "\n",
    "house_prices = pd.read_csv(data_location)\n",
    "\n",
    "input_columns = ['Bedrooms', 'Bathrooms', 'SqFtTotLiving', 'SqFtLot']\n",
    "label_column = 'SalePrice'\n",
    "# x = house_prices.loc[:, input_columns]\n",
    "x = house_prices [input_columns]\n",
    "y = house_prices[[label_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## split train/test = 80% / 20%\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "x_train_orig = x_train\n",
    "x_test_orig = x_test\n",
    "\n",
    "def my_scaler(df):\n",
    "    #return (df-df.min())/(df.max()-df.min())  ## this is min/max scaler\n",
    "    return (df - df.mean()) / df.std()\n",
    "\n",
    "x_train = my_scaler(x_train_orig)\n",
    "x_test = my_scaler (x_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "hidden_1 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 4,545\n",
      "Trainable params: 4,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(x_train.keys())\n",
    "model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(units=64, activation=tf.nn.relu, input_shape=[input_dim], name=\"input_layer\"),\n",
    "                tf.keras.layers.Dense(units=64, activation=tf.nn.relu, name=\"hidden_1\"),\n",
    "                tf.keras.layers.Dense(units=1, name=\"output_layer\")\n",
    "            ])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.01)\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TB logs to :  /tmp/tensorboard-logs/house-prices-regression/2020-01-16--10-18-40\n"
     ]
    }
   ],
   "source": [
    "## tensorboard\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "app_name = 'house-prices-regression' # you can change this, if you like\n",
    "\n",
    "tb_top_level_dir= '/tmp/tensorboard-logs'\n",
    "tensorboard_logs_dir= os.path.join (tb_top_level_dir, app_name, \n",
    "                                    datetime.datetime.now().strftime(\"%Y-%m-%d--%H-%M-%S\"))\n",
    "print (\"Saving TB logs to : \" , tensorboard_logs_dir)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_logs_dir, histogram_freq=1)\n",
    "\n",
    "# Loading of tensorboard in Colab\n",
    "if RUNNING_IN_COLAB:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir tb_top_level_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training starting ...\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 17320 samples, validate on 4330 samples\n",
      "Epoch 1/100\n",
      "17320/17320 [==============================] - 0s 26us/sample - loss: 239816826584.8610 - mean_absolute_error: 371394.0000 - mean_squared_error: 239816753152.0000 - val_loss: 83619204346.2060 - val_mean_absolute_error: 180072.5469 - val_mean_squared_error: 83619201024.0000\n",
      "Epoch 2/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 67210500151.8115 - mean_absolute_error: 158665.9062 - mean_squared_error: 67210518528.0000 - val_loss: 65586991049.1344 - val_mean_absolute_error: 152554.6562 - val_mean_squared_error: 65586978816.0000\n",
      "Epoch 3/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 59260290509.1547 - mean_absolute_error: 146276.4062 - mean_squared_error: 59260297216.0000 - val_loss: 63232715204.1681 - val_mean_absolute_error: 146706.2031 - val_mean_squared_error: 63232729088.0000\n",
      "Epoch 4/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 57248652190.0933 - mean_absolute_error: 142600.7500 - mean_squared_error: 57248653312.0000 - val_loss: 62175042368.4434 - val_mean_absolute_error: 145510.8438 - val_mean_squared_error: 62175039488.0000\n",
      "Epoch 5/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 56297355690.6273 - mean_absolute_error: 141221.3594 - mean_squared_error: 56297349120.0000 - val_loss: 61302758465.7441 - val_mean_absolute_error: 145098.1250 - val_mean_squared_error: 61302759424.0000\n",
      "Epoch 6/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 55383744451.4587 - mean_absolute_error: 140214.1719 - mean_squared_error: 55383724032.0000 - val_loss: 60761350117.5132 - val_mean_absolute_error: 144195.8750 - val_mean_squared_error: 60761366528.0000\n",
      "Epoch 7/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 54656267076.2273 - mean_absolute_error: 139251.4844 - mean_squared_error: 54656253952.0000 - val_loss: 61951041997.6277 - val_mean_absolute_error: 141129.4531 - val_mean_squared_error: 61951049728.0000\n",
      "Epoch 8/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 54502735031.7524 - mean_absolute_error: 138385.1562 - mean_squared_error: 54502752256.0000 - val_loss: 60753329918.6993 - val_mean_absolute_error: 141118.0156 - val_mean_squared_error: 60753342464.0000\n",
      "Epoch 9/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 54027787893.5353 - mean_absolute_error: 137811.6562 - mean_squared_error: 54027821056.0000 - val_loss: 59856656237.3764 - val_mean_absolute_error: 143362.2812 - val_mean_squared_error: 59856650240.0000\n",
      "Epoch 10/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 53748506098.0471 - mean_absolute_error: 137498.7031 - mean_squared_error: 53748498432.0000 - val_loss: 59762658646.9099 - val_mean_absolute_error: 141076.8594 - val_mean_squared_error: 59762667520.0000\n",
      "Epoch 11/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 53626386309.0254 - mean_absolute_error: 136753.6719 - mean_squared_error: 53626388480.0000 - val_loss: 59416892503.0282 - val_mean_absolute_error: 142241.5156 - val_mean_squared_error: 59416883200.0000\n",
      "Epoch 12/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 53246047863.4272 - mean_absolute_error: 136728.2188 - mean_squared_error: 53246058496.0000 - val_loss: 59742976178.3132 - val_mean_absolute_error: 140119.6562 - val_mean_squared_error: 59742973952.0000\n",
      "Epoch 13/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 53212062463.1723 - mean_absolute_error: 136348.8594 - mean_squared_error: 53212073984.0000 - val_loss: 59350669313.4189 - val_mean_absolute_error: 140646.7500 - val_mean_squared_error: 59350675456.0000\n",
      "Epoch 14/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 52981900304.5543 - mean_absolute_error: 136242.0156 - mean_squared_error: 52981915648.0000 - val_loss: 60662612104.2180 - val_mean_absolute_error: 139131.6562 - val_mean_squared_error: 60662620160.0000\n",
      "Epoch 15/100\n",
      "17320/17320 [==============================] - 0s 20us/sample - loss: 53053991442.6827 - mean_absolute_error: 135940.0625 - mean_squared_error: 53053980672.0000 - val_loss: 59814994002.2984 - val_mean_absolute_error: 139590.8438 - val_mean_squared_error: 59814989824.0000\n",
      "Epoch 16/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 52861874694.3852 - mean_absolute_error: 136087.1250 - mean_squared_error: 52861886464.0000 - val_loss: 59556394785.6998 - val_mean_absolute_error: 139609.7188 - val_mean_squared_error: 59556384768.0000\n",
      "Epoch 17/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 52688318630.4887 - mean_absolute_error: 136004.4531 - mean_squared_error: 52688314368.0000 - val_loss: 59933954025.5335 - val_mean_absolute_error: 139496.3594 - val_mean_squared_error: 59933945856.0000\n",
      "Epoch 18/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 52645577142.9247 - mean_absolute_error: 135698.1250 - mean_squared_error: 52645584896.0000 - val_loss: 59687527924.8850 - val_mean_absolute_error: 139048.3125 - val_mean_squared_error: 59687518208.0000\n",
      "Epoch 19/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 52667388009.0014 - mean_absolute_error: 135637.3438 - mean_squared_error: 52667412480.0000 - val_loss: 59464458497.3007 - val_mean_absolute_error: 139259.7656 - val_mean_squared_error: 59464466432.0000\n",
      "Epoch 20/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 52627951691.6767 - mean_absolute_error: 135586.4375 - mean_squared_error: 52627976192.0000 - val_loss: 59968096604.1127 - val_mean_absolute_error: 138797.0938 - val_mean_squared_error: 59968110592.0000\n",
      "Epoch 21/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 52519390189.5538 - mean_absolute_error: 135518.7500 - mean_squared_error: 52519387136.0000 - val_loss: 60343569159.2129 - val_mean_absolute_error: 138702.6719 - val_mean_squared_error: 60343558144.0000\n",
      "Epoch 22/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 52532414315.9575 - mean_absolute_error: 135451.1250 - mean_squared_error: 52532420608.0000 - val_loss: 59418477881.5852 - val_mean_absolute_error: 139038.1406 - val_mean_squared_error: 59418476544.0000\n",
      "Epoch 23/100\n",
      "17320/17320 [==============================] - 0s 19us/sample - loss: 52440015442.0619 - mean_absolute_error: 135369.7188 - mean_squared_error: 52440043520.0000 - val_loss: 59389007165.3691 - val_mean_absolute_error: 138999.3750 - val_mean_squared_error: 59389005824.0000\n",
      "training done.\n",
      "CPU times: user 12.6 s, sys: 813 ms, total: 13.4 s\n",
      "Wall time: 8.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10)\n",
    "\n",
    "epochs = 100\n",
    "print (\"training starting ...\")\n",
    "## TODO : to see training output set verbose=2\n",
    "history = model.fit(\n",
    "              x_train, y_train,\n",
    "              epochs=epochs, validation_split = 0.2, verbose=1,\n",
    "              callbacks=[early_stop, tensorboard_callback])\n",
    "\n",
    "print (\"training done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['mean_squared_error'], label='mse')\n",
    "plt.plot(history.history['mean_absolute_error'], label='mae')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model metrics :  ['loss', 'mean_absolute_error', 'mean_squared_error']\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Metric : loss = 65,023,402,337.38\n",
      "Metric : mean_absolute_error = 134,388.22\n",
      "Metric : mean_squared_error = 65,023,393,792.00\n"
     ]
    }
   ],
   "source": [
    "metric_names = model.metrics_names\n",
    "print (\"model metrics : \" , metric_names)\n",
    "metrics = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "for idx, metric in enumerate(metric_names):\n",
    "    print (\"Metric : {} = {:,.2f}\".format (metric_names[idx], metrics[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>SqFtTotLiving</th>\n",
       "      <th>SqFtLot</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>predicted_price</th>\n",
       "      <th>error</th>\n",
       "      <th>error_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6925</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1350</td>\n",
       "      <td>8742</td>\n",
       "      <td>373300</td>\n",
       "      <td>340397.15625</td>\n",
       "      <td>32902.84375</td>\n",
       "      <td>8.814049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10580</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2460</td>\n",
       "      <td>9975</td>\n",
       "      <td>450000</td>\n",
       "      <td>467254.43750</td>\n",
       "      <td>-17254.43750</td>\n",
       "      <td>3.834319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13379</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2260</td>\n",
       "      <td>5220</td>\n",
       "      <td>485000</td>\n",
       "      <td>520533.56250</td>\n",
       "      <td>-35533.56250</td>\n",
       "      <td>7.326508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1132</td>\n",
       "      <td>2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>830</td>\n",
       "      <td>1034</td>\n",
       "      <td>219950</td>\n",
       "      <td>303786.12500</td>\n",
       "      <td>-83836.12500</td>\n",
       "      <td>38.115992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20942</td>\n",
       "      <td>5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2040</td>\n",
       "      <td>8040</td>\n",
       "      <td>310000</td>\n",
       "      <td>405609.87500</td>\n",
       "      <td>-95609.87500</td>\n",
       "      <td>30.841895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3818</td>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1890</td>\n",
       "      <td>4800</td>\n",
       "      <td>489200</td>\n",
       "      <td>412387.71875</td>\n",
       "      <td>76812.28125</td>\n",
       "      <td>15.701611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22803</td>\n",
       "      <td>3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2660</td>\n",
       "      <td>10004</td>\n",
       "      <td>450000</td>\n",
       "      <td>666534.68750</td>\n",
       "      <td>-216534.68750</td>\n",
       "      <td>48.118819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20370</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2130</td>\n",
       "      <td>2520</td>\n",
       "      <td>567000</td>\n",
       "      <td>493106.62500</td>\n",
       "      <td>73893.37500</td>\n",
       "      <td>13.032341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4536</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2520</td>\n",
       "      <td>3750</td>\n",
       "      <td>735000</td>\n",
       "      <td>605286.50000</td>\n",
       "      <td>129713.50000</td>\n",
       "      <td>17.648095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10743</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3060</td>\n",
       "      <td>6272</td>\n",
       "      <td>504000</td>\n",
       "      <td>683685.75000</td>\n",
       "      <td>-179685.75000</td>\n",
       "      <td>35.651935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5413 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Bedrooms  Bathrooms  SqFtTotLiving  SqFtLot  actual_price  \\\n",
       "6925          3       1.75           1350     8742        373300   \n",
       "10580         5       3.00           2460     9975        450000   \n",
       "13379         3       2.50           2260     5220        485000   \n",
       "1132          2       1.50            830     1034        219950   \n",
       "20942         5       1.75           2040     8040        310000   \n",
       "...         ...        ...            ...      ...           ...   \n",
       "3818          4       1.75           1890     4800        489200   \n",
       "22803         3       2.75           2660    10004        450000   \n",
       "20370         3       2.50           2130     2520        567000   \n",
       "4536          3       2.50           2520     3750        735000   \n",
       "10743         4       2.50           3060     6272        504000   \n",
       "\n",
       "       predicted_price         error  error_percentage  \n",
       "6925      340397.15625   32902.84375          8.814049  \n",
       "10580     467254.43750  -17254.43750          3.834319  \n",
       "13379     520533.56250  -35533.56250          7.326508  \n",
       "1132      303786.12500  -83836.12500         38.115992  \n",
       "20942     405609.87500  -95609.87500         30.841895  \n",
       "...                ...           ...               ...  \n",
       "3818      412387.71875   76812.28125         15.701611  \n",
       "22803     666534.68750 -216534.68750         48.118819  \n",
       "20370     493106.62500   73893.37500         13.032341  \n",
       "4536      605286.50000  129713.50000         17.648095  \n",
       "10743     683685.75000 -179685.75000         35.651935  \n",
       "\n",
       "[5413 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions_df = pd.DataFrame(x_test_orig)  # use the original one, not scaled\n",
    "predictions_df['actual_price'] = y_test\n",
    "predictions_df['predicted_price'] = predictions\n",
    "predictions_df['error'] = predictions_df['actual_price'] - predictions_df['predicted_price'] \n",
    "predictions_df['error_percentage'] = predictions_df['error'].abs() * 100 / predictions_df['actual_price']\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of predictions within benchmark error (5%) are  =  717  (13.2% of total)\n"
     ]
    }
   ],
   "source": [
    "## evaluation\n",
    "benchmark = 5  # 5%\n",
    "good_predictions = predictions_df[predictions_df['error_percentage'] <= benchmark]\n",
    "\n",
    "meeting_benchmark = good_predictions.shape[0] *100 / predictions_df.shape[0]\n",
    "\n",
    "print (\"number of predictions within benchmark error ({}%) are  =  {:,}  ({:.1f}% of total)\".\n",
    "       format (benchmark, good_predictions.shape[0], meeting_benchmark))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
